






[SERVICE]
    # Flush
    # =====
    # Set an interval of seconds before to flush records to a destination
    # Flush        5

    # Daemon
    # ======
    # Instruct Fluent Bit to run in foreground or background mode.
    # Daemon       Off
    Log_Level    debug

    # HTTP Monitoring Server
    # ======================
    #
    # HTTP_Monitor: enable/disable the HTTP Server to monitor
    #               Fluent Bit internals.
    # HTTP_Port   : specify the TCP port of the HTTP Server
    # HTTP_Monitor Off
#     HTTP_Port    2020
#     Parsers_File parser_json.conf

[INPUT]
    name http
    name            http
    port            8888
    listen          0.0.0.0

[FILTER]
    name   grep
    match  *
    regex  $log['kafkaLog']['kafkaEnabled'] true*

[OUTPUT]
    name stdout
    Match *
    format json


[OUTPUT]
    name kafka
    match label.abm_record
    buffer
    brokers broker:29092
    topics  all_log_topic
    message_key_field uuid
    timestamp_format iso8601
    # keep retrying indefinitely from engine level
    # Retry_Limit false
    queue_full_retries 3



[OUTPUT]
    name kafka
    match label.other_log_records
    brokers broker:29092
    topics  all_log_topic
    message_key_field uuid
    timestamp_format iso8601
    # keep retrying indefinitely from engine level
    # Retry_Limit false
    queue_full_retries 3

[OUTPUT]
    Name kafka
    Match *
    # insert your kafka broker url
    brokers broker:29092
    Topics application.log
    Timestamp_Key @timestamp
    Retry_Limit false
    # hides errors "Receive failed: Disconnected" when kafka kills idle connections
    rdkafka.log.connection.close false
    # producer buffer is not included in http://fluentbit.io/documentation/0.12/configuration/memory_usage.html#estimating
    rdkafka.queue.buffering.max.kbytes 10240
    # for logs you'll probably want this ot be 0 or 1, not more
    rdkafka.request.required.acks 1
